Building DAG of jobs...
Using shell: /home/fauverlab/.nextstrain/runtimes/conda/env/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job       count
------  -------
all           1
export        1
total         2

Select jobs to execute...

[Tue Oct 22 14:46:43 2024]
Job 1: Exporting data files for for auspice
Reason: Updated input files: config/lat_longs.tsv, results/branch_lengths.json, config/colors.tsv, results/nt_muts.json, data/metadata.tsv, results/tree.nwk, config/auspice_config.json, results/traits.json, results/aa_muts.json


        augur export v2             --tree results/tree.nwk             --metadata data/metadata.tsv             --node-data results/branch_lengths.json results/traits.json results/nt_muts.json results/aa_muts.json             --colors config/colors.tsv             --lat-longs config/lat_longs.tsv             --auspice-config config/auspice_config.json             --include-root-sequence             --output auspice/WNV_NA.json
        
[Tue Oct 22 14:46:46 2024]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Tue Oct 22 14:46:46 2024]
localrule all:
    input: auspice/WNV_NA.json
    jobid: 0
    reason: Input files updated by another job: auspice/WNV_NA.json
    resources: tmpdir=/tmp

[Tue Oct 22 14:46:46 2024]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2024-10-22T144643.303038.snakemake.log
